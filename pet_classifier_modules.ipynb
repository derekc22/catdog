{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(threshold=torch.inf)\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import glob, os, re\n",
    "import matplotlib.pyplot as plt, matplotlib.pylab as pylab\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPyv_aBBHqD7"
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "  def __init__(self, model_type, training, kwargs):\n",
    "\n",
    "    self.model_type = model_type\n",
    "\n",
    "    if training:\n",
    "      hyperparameters = kwargs.get(\"hyperparameters\")\n",
    "      self.learn_rate = hyperparameters.get(\"learn_rate\")\n",
    "      self.batch_size = hyperparameters.get(\"batch_size\")\n",
    "      self.loss_func = hyperparameters.get(\"loss_func\")\n",
    "      self.reduction = hyperparameters.get(\"reduction\")\n",
    "      self.optimizer = hyperparameters.get(\"optimizer\")\n",
    "      self.lambda_L2 = hyperparameters.get(\"lambda_L2\") \n",
    "      self.dropout_rate = hyperparameters.get(\"dropout_rate\")\n",
    "      self.total_num_correct = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def setOptimizer(self):\n",
    "\n",
    "    if self.optimizer == \"adam\":\n",
    "        self.t = 0\n",
    "        self.weight_moment_list = [[0, 0]]*self.num_layers\n",
    "        self.bias_moment_list = [[0, 0]]*self.num_layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def inference(self, data):\n",
    "    return self.forward(data, training=False)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  def train(self, data, target, save_params=True, epochs=None):\n",
    "\n",
    "    epoch_plt = []\n",
    "    loss_plt = []\n",
    "\n",
    "    if not epochs: \n",
    "      epochs = data.size(dim=1)/self.batch_size\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(1, int(epochs+1)):\n",
    "\n",
    "      data_batch, target_batch = self.batch(data, target)\n",
    "      pred_batch = self.forward(data_batch, training=True)\n",
    "\n",
    "      loss = getattr(self, self.loss_func)(pred_batch, target_batch)\n",
    "\n",
    "      if self.lambda_L2:\n",
    "        loss += self.L2Regularization()\n",
    "      self.backprop(loss)\n",
    "\n",
    "\n",
    "      epoch_plt.append(epoch)\n",
    "      loss_plt.append(loss.item())\n",
    "      train_accuracy = self.calc_train_accuracy(pred_batch, target_batch, epoch)\n",
    "      print(f\"epoch = {epoch}, loss = {loss}, train_accuracy = {train_accuracy} \")\n",
    "      print(f\"__________________________________________\")\n",
    "      \n",
    "    os.makedirs('params/parametersCNN', exist_ok=True)\n",
    "    os.makedirs('params/parametersMLP', exist_ok=True)\n",
    "    self.saveParameters() if save_params else None\n",
    "\n",
    "    \n",
    "\n",
    "    return epoch_plt, loss_plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def calc_train_accuracy(self, pred_batch, target_batch, epoch):\n",
    "    num_correct = torch.sum(torch.abs(pred_batch[:, 0:epoch] - target_batch[0:epoch]) <= 0.5)\n",
    "    self.total_num_correct += num_correct \n",
    "    return (self.total_num_correct/(epoch*self.batch_size))*100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def reduce(self, x):\n",
    "    if self.reduction == \"mean\":\n",
    "      return x.mean()\n",
    "    elif self.reduction == \"sum\":\n",
    "      return x.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def batch(self, data, target):\n",
    "\n",
    "      batch_indicies = torch.randperm(n=data.size(dim=0))[:self.batch_size]  # stochastic\n",
    "\n",
    "      data_batch = data[batch_indicies]\n",
    "      target_batch = target.T[batch_indicies].T\n",
    "\n",
    "      return data_batch, target_batch\n",
    "\n",
    "\n",
    "\n",
    "  def BCELoss(self, pred_batch, target_batch):\n",
    "\n",
    "    epsilon = 1e-8\n",
    "    pred_batch = torch.clamp(pred_batch, epsilon, 1 - epsilon)\n",
    "    errs = target_batch * torch.log(pred_batch) + (1 - target_batch) * torch.log(1 - pred_batch)\n",
    "\n",
    "    bce_loss = -(1/self.batch_size)*torch.sum(errs, dim=0)  # BCE (Binary Cross Entropy) Loss\n",
    "    bce_loss_reduced = self.reduce(bce_loss)\n",
    "\n",
    "    return bce_loss_reduced\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def update(self):\n",
    "\n",
    "    for layer in self.layers:\n",
    "\n",
    "      if self.model_type == \"CNN\" and layer.is_conv_layer:\n",
    "        layer.kernels -= self.learn_rate * layer.kernels.grad\n",
    "        layer.biases -= self.learn_rate * layer.biases.grad\n",
    "\n",
    "      elif self.model_type == \"MLP\":\n",
    "        layer.weights -= self.learn_rate * layer.weights.grad\n",
    "        layer.biases -= self.learn_rate * layer.biases.grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def adam(self, layer_index, gt, param_type, *args):\n",
    "\n",
    "    moment_list = self.weight_moment_list if param_type == \"weight\" else self.bias_moment_list\n",
    "\n",
    "    mt_1, vt_1 = moment_list[layer_index]\n",
    "\n",
    "    \"\"\"Hyperparameter\"\"\"\n",
    "    beta1 = 0.9  # first moment estimate decay rate (smaller = more aggressive)\n",
    "    beta2 = 0.999  # second moment estimate decay rate (smaller = more aggressive)\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    mt = beta1*mt_1 + (1-beta1)*gt\n",
    "    vt = beta2*vt_1 + (1-beta2)*gt**2\n",
    "    mt_hat = mt/(1-beta1**self.t)\n",
    "    vt_hat = vt/(1-beta2**self.t)\n",
    "\n",
    "    moment_list[layer_index] = [mt, vt]\n",
    "\n",
    "    adam_grad = (self.learn_rate*mt_hat)/(torch.sqrt(vt_hat) + epsilon)\n",
    "\n",
    "    return adam_grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def optimizerUpdate(self):\n",
    "\n",
    "    optimizer_func = getattr(self, self.optimizer)\n",
    "\n",
    "    for layer in self.layers:\n",
    "\n",
    "      if self.model_type == \"CNN\" and layer.is_conv_layer:\n",
    "        layer_index = self.layers.index(layer)\n",
    "        layer.kernels -= optimizer_func(layer_index=layer_index, gt=layer.kernels.grad, param_type=\"weight\")\n",
    "        layer.biases -= optimizer_func(layer_index=layer_index, gt=layer.biases.grad, param_type=\"bias\")\n",
    "\n",
    "      elif self.model_type == \"MLP\":\n",
    "        layer_index = self.layers.index(layer)\n",
    "        layer.weights -= optimizer_func(layer_index=layer_index, gt=layer.weights.grad, param_type=\"weight\")\n",
    "        layer.biases -= optimizer_func(layer_index=layer_index, gt=layer.biases.grad, param_type=\"bias\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def L2Regularization(self):\n",
    "\n",
    "      weight_sum = 0\n",
    "\n",
    "      for layer in self.layers:\n",
    "        if self.model_type == \"CNN\" and layer.is_conv_layer:\n",
    "          weight_sum += (torch.sum(layer.kernels ** 2))\n",
    "        elif self.model_type == \"MLP\":\n",
    "          weight_sum += (torch.sum(layer.weights ** 2))\n",
    "\n",
    "\n",
    "      regularization = self.lambda_L2*weight_sum\n",
    "\n",
    "      return regularization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def checkConfig(self, model_config):\n",
    "\n",
    "    config_lengths = [len(v) for k, v in model_config.items()]\n",
    "    all_same_length = all(config_length == config_lengths[0] for config_length in config_lengths)\n",
    "\n",
    "    if not all_same_length:\n",
    "      raise IndexError(f\"{self.model_type} Configuration Error. Recheck sizes of configuration objects\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def printLayers(self):\n",
    "    for layer in self.layers:\n",
    "      print(layer)\n",
    "\n",
    "    if self.model_type == \"CNN\":\n",
    "      for layer in self.MLP.layers:\n",
    "        print(layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def zerograd(self):\n",
    "\n",
    "    for layer in self.layers:\n",
    "\n",
    "      if self.model_type == \"CNN\" and layer.is_conv_layer:\n",
    "        layer.kernels.grad = None\n",
    "        layer.biases.grad = None\n",
    "\n",
    "      elif self.model_type == \"MLP\":\n",
    "        layer.weights.grad = None\n",
    "        layer.biases.grad = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH2952rXHwPG"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def reLU(k):\n",
    "    return k * (k > 0)\n",
    "\n",
    "  @staticmethod\n",
    "  def leakyReLU(k):\n",
    "    alpha = 0.01\n",
    "    k[k < 0] *= alpha\n",
    "    return k\n",
    "\n",
    "  @staticmethod\n",
    "  def sigmoid(k):\n",
    "    return 1/(1 + torch.exp(-k))\n",
    "\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def softmax(k):\n",
    "    k = k - torch.max(k)  # Subtract the max value from the logits to avoid overflow\n",
    "    exp_k = torch.exp(k)\n",
    "    return exp_k / torch.sum(exp_k)\n",
    "\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def none(k):\n",
    "    return k\n",
    "\n",
    "\n",
    "  def activate(self, z, nonlinearity):\n",
    "    return getattr(self, nonlinearity)(z)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od8PWUAfk6Fa"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FullyConnectedLayer(Layer):\n",
    "\n",
    "  def __init__(self, pretrained, device_type, **kwargs):\n",
    "\n",
    "    self.nonlinearity = kwargs.get(\"nonlinearity\")\n",
    "    self.index = int(kwargs.get(\"index\"))\n",
    "\n",
    "\n",
    "    self.device_type = device_type\n",
    "\n",
    "\n",
    "    if not pretrained:\n",
    "\n",
    "      input_count = kwargs.get(\"input_count\")\n",
    "      neuron_count = kwargs.get(\"neuron_count\")\n",
    "\n",
    "      ##### Initialize weights\n",
    "      # self.weights = torch.rand(size=(neuron_count, input_count), dtype=torch.float32)  # Random Initialization\n",
    "\n",
    "      # stddev = np.sqrt(2 / (input_count + neuron_count))\n",
    "      # self.weights = torch.normal(0, stddev, size=(neuron_count, input_count), dtype=torch.float32, device=self.device_type)  # Xavier Initialization\n",
    "\n",
    "      stddev = np.sqrt(2 / input_count)\n",
    "      self.weights = torch.normal(0, stddev, size=(neuron_count, input_count), dtype=torch.float32)  # He Initialization\n",
    "\n",
    "      self.biases = torch.zeros(size=(neuron_count, 1), dtype=torch.float32, device=self.device_type)\n",
    "\n",
    "    else:\n",
    "      self.weights = kwargs.get(\"pretrained_weights\").to(device=self.device_type)\n",
    "      self.biases = kwargs.get(\"pretrained_biases\").to(device=self.device_type)\n",
    "\n",
    "\n",
    "\n",
    "    self.weights.requires_grad_()\n",
    "    self.biases.requires_grad_()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def __repr__(self):\n",
    "    return (f\"__________________________________________\\n\"\n",
    "            f\"MLP Layer {self.index}\\nWeights:\\n{self.weights}\\nBiases:\\n{self.biases}\\nActivation:\\n{self.nonlinearity}\\n\"\n",
    "            f\"__________________________________________\")\n",
    "\n",
    "\n",
    "\n",
    "  def feed(self, x):\n",
    "\n",
    "    z = torch.matmul(self.weights, x) + self.biases\n",
    "\n",
    "    # ####### TESTING THIS ############################\n",
    "    if x.size(dim=1) > 1:\n",
    "      bn1 = nn.BatchNorm1d(num_features=self.weights.size(dim=0), dtype=torch.float32, device=self.device_type)\n",
    "      z = bn1(z.T).T\n",
    "    # ####### TESTING THIS ############################\n",
    "\n",
    "\n",
    "    activations = self.activate(z, self.nonlinearity)\n",
    "\n",
    "\n",
    "    return activations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88U28ZFBISPZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvolutionalLayer(Layer):\n",
    "\n",
    "\n",
    "  def __init__(self, pretrained, is_conv_layer, device_type, **kwargs):\n",
    "\n",
    "    self.is_conv_layer = is_conv_layer\n",
    "    self.padding = 0\n",
    "    self.nonlinearity = kwargs.get(\"nonlinearity\")\n",
    "    self.index = int(kwargs.get(\"index\"))\n",
    "    self.kernel_stride = int(kwargs.get(\"kernel_stride\"))\n",
    "\n",
    "\n",
    "    self.device_type = device_type\n",
    "\n",
    "\n",
    "\n",
    "    if not pretrained:\n",
    "      self.filter_count = kwargs.get(\"filter_count\")\n",
    "      self.kernel_height, self.kernel_width = kwargs.get(\"kernel_shape\")\n",
    "\n",
    "      # Random Initilization\n",
    "      self.kernels = torch.rand(size=(1, self.filter_count, self.kernel_height, self.kernel_width), dtype=torch.float32, device=self.device_type) if is_conv_layer else torch.empty(size=(1, self.filter_count, self.kernel_height, self.kernel_width), dtype=torch.float32, device=self.device_type)\n",
    "      self.biases = torch.rand(size=(1, self.filter_count, 1), dtype=torch.float32, device=self.device_type) if is_conv_layer else None\n",
    "\n",
    "    else:\n",
    "      self.kernels = kwargs.get(\"pretrained_kernels\")\n",
    "      self.biases = kwargs.get(\"pretrained_biases\")\n",
    "      self.filter_count, self.kernel_height, self.kernel_width = self.kernels.size()[-3:]\n",
    "\n",
    "\n",
    "    if is_conv_layer:\n",
    "      self.kernels.requires_grad_()\n",
    "      self.biases.requires_grad_()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def __repr__(self):\n",
    "\n",
    "    return (f\"__________________________________________\\n\"\n",
    "            f\"CNN Layer {self.index}\\nKernels:\\n{self.kernels}\\nKernel Size: {self.kernels.size()}\\nBiases:\\n{self.biases}\\nBias Size: {self.biases.size() if self.biases is not None else None}\\nActivation: {self.nonlinearity}\\n\"\n",
    "            f\"__________________________________________\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def traverse(self, imgs, func):\n",
    "\n",
    "    if imgs.ndim == 3:\n",
    "      imgs = imgs.unsqueeze(dim=1)\n",
    "\n",
    "    img_batch_size, img_channel_count, img_height, img_width = imgs.size()\n",
    "\n",
    "    img_slices_stack = imgs.unfold(dimension=2, size=self.kernel_height, step=self.kernel_stride).unfold(dimension=3, size=self.kernel_width, step=self.kernel_stride).reshape(img_batch_size, img_channel_count, -1, self.kernel_height, self.kernel_width)\n",
    "    img_slices_stack = img_slices_stack.to(self.device_type)\n",
    "\n",
    "    result = func(img_slices_stack)\n",
    "\n",
    "    feature_map_rows = int(((img_height - self.kernel_height + 2*self.padding)/self.kernel_stride) + 1)\n",
    "    feature_map_cols = int(((img_width - self.kernel_width + 2*self.padding)/self.kernel_stride) + 1)\n",
    "    feature_map = result.reshape(img_batch_size, self.filter_count, feature_map_rows, feature_map_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if self.is_conv_layer:\n",
    "\n",
    "      # ####### TESTING THIS ############################\n",
    "      # if img_batch_size > 1:\n",
    "      bn2 = nn.BatchNorm2d(num_features=self.filter_count, dtype=torch.float32, device=self.device_type)\n",
    "      feature_map = bn2(feature_map)\n",
    "      # ####### TESTING THIS ############################\n",
    "\n",
    "      feature_map = self.activate(feature_map, self.nonlinearity)\n",
    "\n",
    "    feature_map = feature_map.to(self.device_type)\n",
    "\n",
    "\n",
    "    return feature_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, x):\n",
    "\n",
    "    def f(img_slices_stack):\n",
    "\n",
    "      result = torch.einsum('bcshw,bfhw->bfshw', img_slices_stack, self.kernels)\n",
    "      result = torch.sum(result, dim=(3, 4)) + self.biases\n",
    "\n",
    "      return result\n",
    "\n",
    "    return self.traverse(x, func=f)\n",
    "\n",
    "\n",
    "\n",
    "  def maxpool(self, x):\n",
    "\n",
    "    def f(img_slices_stack):\n",
    "\n",
    "      result = img_slices_stack.max(dim=3)[0].max(dim=3)[0]\n",
    "\n",
    "      return result\n",
    "\n",
    "    return self.traverse(x, func=f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ogXVjxIk0c9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLP(Network):\n",
    "\n",
    "  def __init__(self, pretrained, training, device_type, **kwargs):\n",
    "\n",
    "    super().__init__(model_type=\"MLP\", training=training, kwargs=kwargs)\n",
    "\n",
    "    self.device_type = device_type\n",
    "\n",
    "    if not pretrained:\n",
    "      mlp_model_config = kwargs.get(\"mlp_model_config\")\n",
    "      self.checkConfig(model_config=mlp_model_config)\n",
    "      self.layers = self.buildLayers(mlp_model_config=mlp_model_config, input_feature_count=kwargs.get(\"input_feature_count\"))\n",
    "    else:\n",
    "      self.layers = self.loadLayers(mlp_model_params=kwargs.get(\"mlp_model_params\"))\n",
    "\n",
    "    self.num_layers = len(self.layers)\n",
    "\n",
    "    if training and self.optimizer:\n",
    "      self.setOptimizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def loadLayers(self, mlp_model_params):\n",
    "    layers = [FullyConnectedLayer(pretrained=True, device_type=self.device_type, pretrained_weights=weights, pretrained_biases=biases, nonlinearity=nonlinearity, index=index) for (weights, biases, nonlinearity, index) in mlp_model_params.values()]\n",
    "    return layers\n",
    "\n",
    "\n",
    "  def buildLayers(self, mlp_model_config, input_feature_count):\n",
    "\n",
    "    neuron_counts = mlp_model_config.get(\"neuron_counts\")\n",
    "    activation_functions = mlp_model_config.get(\"MLP_activation_functions\")\n",
    "\n",
    "    neuron_counts.insert(0, input_feature_count)\n",
    "\n",
    "    layers = [FullyConnectedLayer(pretrained=False, device_type=self.device_type, input_count=neuron_counts[i], neuron_count=neuron_counts[i+1], nonlinearity=activation_functions[i], index=i+2) for i in range(len(neuron_counts)-1)]\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "  def saveParameters(self):\n",
    "    for layer in self.layers:\n",
    "      layer.index = \"0\" + str(layer.index) if layer.index < 10 else layer.index\n",
    "      torch.save(layer.weights, f\"params/parametersMLP/layer_{layer.index}_weights_{layer.nonlinearity}.pth\")\n",
    "      torch.save(layer.biases, f\"params/parametersMLP/layer_{layer.index}_biases_{layer.nonlinearity}.pth\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, curr_input, training):\n",
    "    for layer in self.layers:\n",
    "\n",
    "      curr_input = layer.feed(curr_input)\n",
    "\n",
    "      if training and self.dropout_rate and layer != self.layers[-1]:\n",
    "        curr_input = self.dropout(curr_input)\n",
    "\n",
    "    return curr_input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def dropout(self, curr_input):\n",
    "\n",
    "    drop_count = int(self.dropout_rate * curr_input.numel())\n",
    "    dropout_row_indicies = torch.randint(low=0, high=curr_input.size(dim=0), size=(drop_count,))\n",
    "    dropout_col_indicies = torch.randint(low=0, high=curr_input.size(dim=1), size=(drop_count,))\n",
    "\n",
    "    curr_input[dropout_row_indicies, dropout_col_indicies] = 0\n",
    "\n",
    "    return curr_input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def backprop(self, loss):\n",
    "\n",
    "    self.zerograd()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      if not self.optimizer:\n",
    "        for layer in self.layers:\n",
    "          self.update(layer)\n",
    "      else:\n",
    "        self.t += 1\n",
    "        for layer in self.layers:\n",
    "          self.optimizerUpdate(layer)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZmrcc0rk0Ns"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CNN(Network):\n",
    "\n",
    "  def __init__(self, pretrained, device_type, training, **kwargs):\n",
    "\n",
    "    super().__init__(model_type=\"CNN\", training=training, kwargs=kwargs)\n",
    "\n",
    "    self.device_type = device_type\n",
    "\n",
    "    if not pretrained:\n",
    "      cnn_model_config = kwargs.get(\"cnn_model_config\")\n",
    "      self.checkConfig(model_config=cnn_model_config)\n",
    "      self.layers = self.buildLayers(cnn_model_config=cnn_model_config)\n",
    "\n",
    "      MLP_input_feature_count = self.calcMLPInputSize(kwargs.get(\"input_data_dim\"))\n",
    "      self.MLP = MLP(pretrained=False, device_type=self.device_type, training=training, input_feature_count=MLP_input_feature_count, mlp_model_config=kwargs.get(\"mlp_model_config\"), hyperparameters=kwargs.get(\"mlp_hyperparameters\"))\n",
    "    else:\n",
    "      self.layers = self.loadLayers(kwargs.get(\"cnn_model_params\"))\n",
    "      self.MLP = MLP(pretrained=True, device_type=self.device_type, training=training, mlp_model_params=kwargs.get(\"mlp_model_params\"), hyperparameters=kwargs.get(\"mlp_hyperparameters\"))\n",
    "\n",
    "\n",
    "    self.num_layers = len(self.layers)\n",
    "\n",
    "    if training and self.optimizer:\n",
    "      self.setOptimizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def loadLayers(self, cnn_model_params):\n",
    "\n",
    "    layers = [ConvolutionalLayer(pretrained=True, device_type=self.device_type, is_conv_layer=(is_conv_layer == \"True\"), pretrained_kernels=kernels, pretrained_biases=biases, nonlinearity=nonlinearity, kernel_stride=stride, index=index) for (is_conv_layer, kernels, biases, nonlinearity, stride, index) in cnn_model_params.values()]\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "  def buildLayers(self, cnn_model_config):\n",
    "\n",
    "    is_conv_layer = cnn_model_config.get(\"is_conv_layer\")\n",
    "    filter_counts = cnn_model_config.get(\"filter_counts\")\n",
    "    kernel_shapes = cnn_model_config.get(\"kernel_shapes\")\n",
    "    kernel_strides = cnn_model_config.get(\"kernel_strides\")\n",
    "    activation_functions = cnn_model_config.get(\"CNN_activation_functions\")\n",
    "    num_layers = len(is_conv_layer)\n",
    "\n",
    "    layers = [ConvolutionalLayer(pretrained=False, device_type=self.device_type, is_conv_layer=is_conv_layer[i], filter_count=filter_counts[i], kernel_shape=kernel_shapes[i], kernel_stride=kernel_strides[i], nonlinearity=activation_functions[i], index=i+1) for i in range(num_layers)]\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "\n",
    "  def saveParameters(self):\n",
    "    for layer in self.layers:\n",
    "      layer.index = \"0\" + str(layer.index) if layer.index < 10 else layer.index\n",
    "      torch.save(layer.kernels, f\"params/parametersCNN/cnn_layer_{layer.index}_kernels_{layer.nonlinearity}_{layer.is_conv_layer}_{layer.kernel_stride}.pth\")\n",
    "      torch.save(layer.biases, f\"params/parametersCNN/cnn_layer_{layer.index}_biases_{layer.nonlinearity}_{layer.is_conv_layer}_{layer.kernel_stride}.pth\")\n",
    "\n",
    "    self.MLP.saveParameters()\n",
    "\n",
    "\n",
    "\n",
    "  def calcMLPInputSize(self, input_data_dim):\n",
    "\n",
    "    print(\"calculating MLP input size.......\")\n",
    "\n",
    "    input_data_dim = (1, ) + input_data_dim\n",
    "\n",
    "    dummy_data = torch.empty(size=input_data_dim, device=self.device_type)\n",
    "    dummy_MLP_input = self.forward(dummy_data, training=True, dummy=True)\n",
    "    dummy_MLP_input_feature_count = dummy_MLP_input.size(dim=0)\n",
    "\n",
    "    return dummy_MLP_input_feature_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, curr_input, training, dummy=False):\n",
    "\n",
    "    for layer in self.layers:\n",
    "      if layer.is_conv_layer:\n",
    "\n",
    "        curr_input = layer.convolve(curr_input)\n",
    "\n",
    "      else:\n",
    "        curr_input = layer.maxpool(curr_input)\n",
    "\n",
    "\n",
    "    curr_input_batch_size = curr_input.size(dim=0)\n",
    "    flattened_feature_map = curr_input.view(curr_input_batch_size, -1).to(torch.float32).T\n",
    "\n",
    "    if dummy:\n",
    "      return flattened_feature_map\n",
    "    else:\n",
    "      return self.MLP.forward(flattened_feature_map, training=training)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def backprop(self, loss):\n",
    "\n",
    "    self.zerograd()\n",
    "    self.MLP.zerograd()\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      if not self.optimizer:\n",
    "        self.update()\n",
    "      else:\n",
    "        self.t += 1\n",
    "        self.optimizerUpdate()\n",
    "\n",
    "\n",
    "      if not self.MLP.optimizer:\n",
    "        self.MLP.update()\n",
    "      else:\n",
    "        self.MLP.t += 1\n",
    "        self.MLP.optimizerUpdate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oj7pBSvSQT4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(dataset_size, img_batch, label_batch, prediction_batch, display_results=True):\n",
    "\n",
    "\n",
    "  if dataset_size == 1:\n",
    "\n",
    "    predicted_animal = \"dog\" if prediction_batch.item() >= 0.5 else \"cat\"\n",
    "    animal_label = \"dog\" if label_batch.item() == 1 else \"cat\"\n",
    "\n",
    "    # print(f\"prediction = {predicted_animal}\")\n",
    "    # print(f\"label      = {animal_label}\")\n",
    "\n",
    "    img_batch = img_batch.cpu()\n",
    "\n",
    "    plt.imshow(img_batch.squeeze(), cmap='gray')\n",
    "    plt.title(f'Prediction: {predicted_animal}, Label: {animal_label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "  else:\n",
    "\n",
    "    predictions = [\"dog\" if pet >= 0.5 else \"cat\" for pet in prediction_batch[0].tolist()]\n",
    "    labels = [\"dog\" if pet_label == 1 else \"cat\" for pet_label in label_batch.tolist()]\n",
    "    \n",
    "    # print(f\"predictions = {predictions}\")\n",
    "    # print(f\"labels      = {labels}\")\n",
    "\n",
    "    num_correct = torch.sum(torch.abs(prediction_batch - label_batch) <= 0.5)\n",
    "    print(f\"number correct = {num_correct.item()}/{dataset_size}\")\n",
    "\n",
    "    percent_correct = (num_correct/dataset_size)*100\n",
    "    print(f\"accuracy = {percent_correct.item()}%\\n\\n\")\n",
    "\n",
    "    if display_results:\n",
    "      for (img, pred, lbl) in zip(img_batch, predictions, labels):\n",
    "        img = img.cpu()\n",
    "\n",
    "        plt.imshow(img.squeeze(), cmap='gray') # grey images\n",
    "        plt.title(f'Prediction: {pred}, Label: {lbl}')\n",
    "\n",
    "        plt.show(block=False)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plotTrainingResults(epoch_plt, loss_plt):\n",
    "\n",
    "  epoch_plt = torch.tensor(epoch_plt)\n",
    "  loss_plt = torch.tensor(loss_plt)\n",
    "  print(f\"mean loss = {loss_plt.mean()}\")\n",
    "\n",
    "  plt.figure(1)\n",
    "  marker_size = 1\n",
    "  f = plt.scatter(epoch_plt[:], loss_plt[:], s=marker_size)\n",
    "  plt.xlabel(\"epoch\")\n",
    "  plt.ylabel(\"loss\")\n",
    "  plt.title(f\"mean loss = {loss_plt.mean()}\")\n",
    "  plt.grid()\n",
    "\n",
    "  z = np.polyfit(epoch_plt, loss_plt, 5)\n",
    "  p = np.poly1d(z)\n",
    "  pylab.plot(epoch_plt, p(epoch_plt), \"r--\")\n",
    "\n",
    "  plt.savefig('lossPlot.pdf')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def fetchMLPParametersFromFile(device_type, directory):\n",
    "\n",
    "  modelParams = {}\n",
    "\n",
    "  weight_pattern = \"layer_*_weights_*.pth\"  # Pattern to match\n",
    "  weight_files = glob.glob(os.path.join(directory, weight_pattern))\n",
    "  weight_files.sort()\n",
    "\n",
    "  bias_pattern = \"layer_*_biases_*.pth\"  # Pattern to match\n",
    "  bias_files = glob.glob(os.path.join(directory, bias_pattern))\n",
    "  bias_files.sort()\n",
    "\n",
    "\n",
    "  for (w_file, b_file) in zip(weight_files, bias_files):\n",
    "\n",
    "    weights = torch.load(w_file, map_location=device_type, weights_only=True)\n",
    "    biases = torch.load(b_file, map_location=device_type, weights_only=True)\n",
    "\n",
    "    regex_pattern = r\"layer_(\\d+)_weights_(.*?)\\.pth\"\n",
    "    match = re.search(regex_pattern, w_file)\n",
    "\n",
    "    index = match.group(1)\n",
    "    activation = match.group(2)\n",
    "\n",
    "    modelParams.update({f\"Layer {index}\": [weights, biases, activation, index] })\n",
    "\n",
    "  return modelParams\n",
    "\n",
    "\n",
    "\n",
    "def fetchCNNParametersFromFile(device_type, directory):\n",
    "\n",
    "  modelParams = {}\n",
    "\n",
    "  kernel_pattern = \"cnn_layer_*_kernels_*_*_*.pth\"  # Pattern to match\n",
    "  kernel_files = glob.glob(os.path.join(directory, kernel_pattern))\n",
    "  kernel_files.sort()\n",
    "\n",
    "  bias_pattern = \"cnn_layer_*_biases_*_*_*.pth\"  # Pattern to match\n",
    "  bias_files = glob.glob(os.path.join(directory, bias_pattern))\n",
    "  bias_files.sort()\n",
    "\n",
    "\n",
    "  for (k_file, b_file) in zip(kernel_files, bias_files):\n",
    "\n",
    "    kernels = torch.load(k_file, map_location=device_type, weights_only=True)\n",
    "    biases = torch.load(b_file, map_location=device_type, weights_only=True)\n",
    "\n",
    "    regex_pattern = r\"cnn_layer_(\\d+)_kernels_(\\w+)_([\\w]+)_(\\d+)\\.pth\"\n",
    "\n",
    "    match = re.search(regex_pattern, k_file)\n",
    "\n",
    "    index = match.group(1)\n",
    "    activation = match.group(2)\n",
    "    is_conv = match.group(3)\n",
    "    stride = match.group(4)\n",
    "\n",
    "    modelParams.update({f\"CNN Layer {index}\": [is_conv, kernels, biases, activation, stride, index] })\n",
    "\n",
    "  return modelParams\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def select_random_file(label, transform, use):\n",
    "\n",
    "  folder_path = f\"{use}dataset/{label}sfolder\"\n",
    "\n",
    "  files = [\n",
    "    f for f in os.listdir(folder_path)\n",
    "    if os.path.isfile(os.path.join(folder_path, f)) \n",
    "    and not f.startswith('.')\n",
    "    and not f.startswith('._')\n",
    "  ]\n",
    "\n",
    "  # Select a random file\n",
    "  random_file = random.choice(files)\n",
    "  image_path = os.path.join(folder_path, random_file)\n",
    "\n",
    "  image = Image.open(image_path)\n",
    "\n",
    "  image_tensor = transform(image)\n",
    "  return image_tensor\n",
    "\n",
    "\n",
    "\n",
    "def genEE364PetImageStack(dataset_size, img_height, img_width, color_channels, use, device_type):\n",
    "\n",
    "  # Create dataset transformation\n",
    "  transformations = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "  ]\n",
    "\n",
    "  if color_channels == 1:\n",
    "    transformations.append(transforms.Grayscale(num_output_channels=1))\n",
    "    transform = transforms.Compose(transformations)\n",
    "\n",
    "  # Preallocate tensors for the entire dataset\n",
    "  data_tensors = torch.zeros((dataset_size, color_channels, img_height, img_width), device=device_type)  # Assuming RGB images\n",
    "  target_tensors = torch.zeros(dataset_size, device=device_type)\n",
    "\n",
    "  for n in range(dataset_size):\n",
    "    # print(f\"preparing data.... {((n/dataset_size)*100):.2f}%\") if n % 20 == 0 else None\n",
    "    # Generate random index and select seed\n",
    "\n",
    "    label_int = random.randint(0, 1)\n",
    "    label = \"dog\" if label_int == 1 else \"cat\"\n",
    "\n",
    "    image_tensor = select_random_file(label, transform, use)\n",
    "\n",
    "    # Insert into preallocated tensor\n",
    "    data_tensors[n] = image_tensor\n",
    "    target_tensors[n] = label_int\n",
    "\n",
    "  return data_tensors, target_tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pth_to_pkl(source_folder, target_folder):\n",
    "\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(source_folder):\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        \n",
    "        if os.path.isfile(source_path):\n",
    "\n",
    "            data = torch.load(source_path)\n",
    "            \n",
    "            target_filename = f\"{os.path.splitext(filename)[0]}.pkl\"\n",
    "            target_path = os.path.join(target_folder, target_filename)\n",
    "            \n",
    "            with open(target_path, 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "            \n",
    "            print(f\"Converted {filename} to {target_filename}\")\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
